## 算法相关

1. 实现一个快速排序

2. 实现归并排序

   ```java
   package com.learn.sort;
   
   /**
    * ClassName: Demo3
    * Function: TODO ADD FUNCTION.
    * Reason: TODO ADD REASON(可选).
    * Date: 2020-08-29 16:19
    *
    * @author sjxuwei
    * @since JDK 1.8
    */
   
   /**
    * 归并排序
    * 二分法
    */
   public class Demo3 {
       public static void main(String[] args) {
           int[] arr  = {2,3,4,6,7,8,-1,2};
   
           sort(arr);
   
           for(int i = 0;i <arr.length;i++){
               System.out.print(arr[i] +" ");
           }
       }
       private static void sort(int[] arr) {
           int[] temp = new int[arr.length];
           fen(arr,0,arr.length - 1,temp);
       }
   
       //分
       private static void fen(int[] arr, int start, int end,int[] temp) {
           if(start < end) {
               //左
               int startLeft = start;
               int mid = (startLeft + end) / 2;
               int endRight = end;
   
               fen(arr, start, mid, temp);
               //右
               fen(arr, mid + 1, end, temp);
   
               merge(arr, startLeft, mid, endRight, temp);
           }
       }
   
       //合
       private static void merge(int[] arr, int start,int mid, int end,int[] temp) {
           int startLeft = start;
           int endLeft = mid;
           int startRight = mid +1;
           int endRight = end;
   
           int tempIndex = 0;
   
           while(startLeft <= endLeft && startRight <= endRight){
                   if(arr[startLeft] < arr[startRight]){
                       temp[tempIndex++] = arr[startLeft++];
                       break;
                   }else {
                       temp[tempIndex++] = arr[startRight++];
                   }
           }
           while (startLeft <= endLeft){
               temp[tempIndex++] = arr[startLeft++];
           }
   
           while (startRight <= endRight){
               temp[tempIndex++] = arr[startRight++];
           }
   
           tempIndex = 0;
           int tempLeft = start;
           while (tempLeft <= end){
               arr[tempLeft++] = temp[tempIndex++];
           }
       }
   }
   ```

   

3. [1,2,3,5,7,8,9] 组合成 15 有多少种情况，设计一个算法实现 

   ```java
   package com.learn.sort;
   
   /**
    * ClassName: Demo04
    * Function: TODO ADD FUNCTION.
    * Reason: TODO ADD REASON(可选).
    * Date: 2020-08-29 17:37
    *
    * @author sjxuwei
    * @since JDK 1.8
    */
   
   import java.util.*;
   
   /**
    * [1,2,3,5,7,8,9] 组合成 15 有多少种情况，设计一个算法实现
    */
   public class Demo04 {
       static List<List<Integer>> result = new ArrayList<>();
       public static void main(String[] args) {
           int[] arr = {1,2,3,5,7,8,9};
           //先排序
           Arrays.sort(arr);
           combinationSum(arr,15);
           System.out.println(result);
       }
   
       private static void combinationSum(int[] arr,int target){
           List<Integer> r = new ArrayList<>();
           find(arr,0,target,r);
       }
   
       private static void find(int[] arr, int start,int target,List<Integer> r) {
           if(target == 0){
               result.add(new ArrayList<>(r));
               return;
           }
           for(int i = start;i < arr.length;i++){
               if(target - arr[i] < 0){
                   break;
               }
   
               r.add(arr[i]);
               find(arr,i + 1,target - arr[i],r);
               r.remove(r.size() - 1);
           }
       }
   
   
   }
   ```

   


## 框架相关

1. spark调优问题
2. hadoop调优问题
   * 如果输入端小文件过多，可以在输入的时候对小文件进行合并，采用ConbinFileInputFormat
   * 减少环形缓冲溢写到磁盘的次数，也就是适当调大环形缓冲的值io.sort.mb(环形缓冲大小)，sort.spill.persent(发生溢写时的因子)
   * map之后先进行一次combine处理
   * 将map和reduce设置成并行运行
   * 数据在进入reduce时会进入换成，如果不进行设置，缓冲中的数据会先写入到磁盘再读磁盘写入到reduce，可以设置一部分数据直接从缓冲进入reduce(mapred.job.reduce.input.buffer.percent)
   * 压缩中间传输数据
   * 可以适当将map的超时时间调大
   * 适当的调整yarn调度一个任务时，最大可允许开启的map和reduce个数
3. spark streaming 和 kafka对接两种方式及原理
4. MapReduce的运行原理
5. 针对于大量小文件该如何处理，map端并行度如何缩小
   * 输入端小文件
     * 可以在数据输入时对文件进行合并，使用CombinFileInputFormat输入
   * 输出端小文件
     * 输出时要尽量避免产生大量的小文件，如果已经产生了小文件，那么可以对这些文件进行归档，将其打包成一个har文件进行存储，方便namenode管理。
   * map并行度如何缩小
     * 可以通过参数设置一个任务的最大map数	
     * 输入是尽量做文件的合并，一般来说map的数量是切片的数量，有几种切片规则，按照文件来切片，按照大小来切片（128M为一块）
6. mysql底层原理，B树和B+树的原理区别
7. HBase底层原理是树吗
8. HBase基于hdfs是如何做到可以数据更新的，hbase数据更新的原理
9. hbase的region合并原理，storefile合并原理

## jvm

1. jvm内存模型
2. 什么是stop the word ， 什么情况会发生
3. jdk1.8的synchronized锁底层原理
   * 他采用了一个监视器，经过反编译后就会发现，当开启一个锁是，会注册一个monitor，而当释放锁时，会有一个monitorexit操作
4. HashMap底层原理
5. juc的线程锁原理为什么比synchronized高效
6. 垃圾回收器的种类，垃圾回收算法的种类，垃圾回收算法原理
7. 新生代和老年代分别是什么方式的内存回收机制

你工作过中遇到的难题有哪些，怎么解决的
有没有看过spark源码
有没有看过MapReduce源码
有没有看过HBase源码

